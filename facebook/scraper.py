import time
import csv
import hashlib
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.action_chains import ActionChains
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC


# ------------------------------------------------
# å•Ÿå‹• Selenium
# ------------------------------------------------
options = webdriver.ChromeOptions()
options.add_argument("--disable-notifications")
driver = webdriver.Chrome(options=options)

# ------------------------------------------------
# é€²å…¥è²¼æ–‡ç¶²å€
# ------------------------------------------------
POST_URL = "https://www.facebook.com/lefthere036/posts/pfbid02p6akqs7knutGbe96utxdvV5SYNZ41bTyGjUeBiqTN94KLTHXzEKpQWeFfJ9zaCz4l"
driver.get(POST_URL)

input("ç™»å…¥å¥½è«‹æŒ‰ä»»æ„éµï¼š ")


# ------------------------------------------------
# CSVï¼šåˆå§‹åŒ–
# ------------------------------------------------
csv_file = open("fb_comments.csv", "a", newline="", encoding="utf-8-sig")
csv_writer = csv.writer(csv_file)
csv_writer.writerow(["comment_id", "author", "content"])


# ------------------------------------------------
# å·¥å…·å‡½å¼ï¼šç”¢ç”Ÿå”¯ä¸€ ID
# ------------------------------------------------
def make_hash(text):
    return hashlib.md5(text.encode("utf-8")).hexdigest()


# ------------------------------------------------
# æ‰¾åˆ°ç•™è¨€å€ï¼ˆFacebook çš„ç•™è¨€å€ä¸¦æ²’æœ‰å›ºå®š selectorï¼Œéœ€è¦ç­‰å¾…ç¬¬ä¸€å‰‡ç•™è¨€å‡ºç¾ï¼‰
# ------------------------------------------------
def find_comment_section():
    print("å°‹æ‰¾è©•è«–å€åŸŸ...")

    # ==========================
    # 1ï¸âƒ£ å„ªå…ˆä½¿ç”¨ä½ æ‰¾åˆ°çš„ scroll container suspect
    # ==========================
    suspect_selector = (
        "//div[contains(@class, 'x14z9mp') and "
        "contains(@class,'xat24cr') and "
        "contains(@class,'x1lziwak') and "
        "contains(@class,'xexx8yu') and "
        "contains(@class,'xyri2b') and "
        "contains(@class,'x18d9i69') and "
        "contains(@class,'x1c1uobl') and "
        "contains(@class,'x1gslohp')]"
    )

    suspect_sections = driver.find_elements(By.XPATH, suspect_selector)
    for i, sec in enumerate(suspect_sections):
        if sec.is_displayed() and sec.size["height"] > 200:
            print(f"æ‰¾åˆ°ç–‘ä¼¼ç•™è¨€å€ scroll containerï¼š#{i+1} é«˜åº¦={sec.size['height']}")
            return sec

    # ==========================
    # 2ï¸âƒ£ ç¬¬äºŒå„ªå…ˆï¼šå¸¸è¦‹çš„ç•™è¨€ scroll container (x1n2onr6)
    # ==========================
    primary_selector = "//div[contains(@class,'x1n2onr6')]"
    sections = driver.find_elements(By.XPATH, primary_selector)

    for i, sec in enumerate(sections):
        try:
            if sec.is_displayed() and sec.size["height"] > 200:

                print(f"æ‰¾åˆ°ä¸»è¦è©•è«–å€åŸŸ: {i+1}, é«˜åº¦={sec.size['height']}")

                # æ¸¬è©¦é€™å€‹å…ƒç´ æ˜¯å¦çœŸçš„èƒ½æ»¾å‹•
                before = driver.execute_script("return arguments[0].scrollTop;", sec)
                driver.execute_script("arguments[0].scrollTop = arguments[0].scrollHeight;", sec)
                time.sleep(0.3)
                after = driver.execute_script("return arguments[0].scrollTop;", sec)

                if after > before:
                    print(" â†’ ç¢ºèªæ­¤å…ƒç´ å¯æ»¾å‹• âœ”")
                    return sec
                else:
                    print(" â†’ æ­¤å…ƒç´ ä¸å¯æ»¾å‹•ï¼Œè·³é âœ˜")

        except Exception as e:
            continue

    print("ä¸»è¦è©•è«–å€åŸŸæœªæ‰¾åˆ°ï¼Œé€€å›æ¬¡è¦æœå°‹...")

    # ==========================
    # 3ï¸âƒ£ fallback selectors
    # ==========================

    fallback_selectors = [
        # é€™å…©å€‹ class å¹¾ä¹å¿…å®šå‡ºç¾åœ¨çœŸæ­£ scroll container
        "//div[contains(@class,'x78zum5') and contains(@class,'x1n2onr6')]",
        "//div[contains(@class,'x1n2onr6')]",
    ]

    for selector in fallback_selectors:
        sections = driver.find_elements(By.XPATH, selector)
        for sec in sections:
            try:
                if sec.is_displayed() and sec.size["height"] > 150:
                    print(f"fallback æ‰¾åˆ°å€åŸŸï¼Œé«˜åº¦={sec.size['height']}")
                    return sec
            except:
                continue

    print("æœ€çµ‚æœªæ‰¾åˆ°ç‰¹å®šå€åŸŸï¼Œä½¿ç”¨å…¨å±€æ»¾å‹•")
    return None


# ------------------------------------------------
# å±•é–‹ç•™è¨€ / å›è¦†
# ------------------------------------------------
def expand_all_buttons():
    '''changed = False

    # æ‰€æœ‰å¯èƒ½çš„å±•é–‹æŒ‰éˆ•æ–‡å­—ï¼ˆç¹ä¸­ + è‹±æ–‡ï¼‰
    keywords = [
        "æŸ¥çœ‹å…¶ä»–", "æŸ¥çœ‹ä¹‹å‰", "æŸ¥çœ‹æ›´å¤š", "æ›´å¤šå›è¦†",
        "View more", "View previous", "See more"
    ]

    for text in keywords:
        buttons = driver.find_elements(By.XPATH, f"//span[contains(text(), '{text}')]")

        for btn in buttons:
            try:
                driver.execute_script("arguments[0].scrollIntoView(true);", btn)
                time.sleep(0.3)
                btn.click()
                time.sleep(1)
                changed = True
            except:
                pass

    return changed'''
    changed = False

    # å°‹æ‰¾æ‰€æœ‰å¯èƒ½çš„å±•é–‹æŒ‰éˆ•
    button_selectors = [
        # å±•é–‹å›è¦†
        "//span[contains(text(), 'å‰‡å›è¦†')]/ancestor::div[@role='button']",
        "//span[contains(text(), 'æ¡å›å¤')]/ancestor::div[@role='button']",

        # å±•é–‹æ›´å¤šç•™è¨€
        "//span[contains(text(), 'æ›´å¤šç•™è¨€')]/ancestor::div[@role='button']",
        "//div[@role='button'][contains(text(), 'æ›´å¤šç•™è¨€')]",

        # æŸ¥çœ‹ä¹‹å‰çš„ç•™è¨€
        "//div[@role='button'][contains(text(), 'æŸ¥çœ‹ä¹‹å‰çš„ç•™è¨€')]",

        # æŸ¥çœ‹æ›´å¤šç•™è¨€/å›è¦†
        "//span[contains(text(), 'æŸ¥çœ‹æ›´å¤š')]/ancestor::div[@role='button']",
    ]
    
    buttons = driver.find_elements(By.XPATH, " | ".join(button_selectors))
    for btn in buttons:
        try:
            driver.execute_script("arguments[0].scrollIntoView({block:'center'});", btn)
            time.sleep(0.5)
            btn.click()
            print("clicked button")
            time.sleep(1.5)
            changed = True
        except:
            pass
    return changed


# ------------------------------------------------
# æ»¾å‹•é é¢ç›´åˆ°é«˜åº¦æ”¹è®Š
# ------------------------------------------------
def scroll_page():
    old_height = driver.execute_script("return document.body.scrollHeight")
    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
    print("scrolled_page_sleep:")
    time.sleep(1.2)
    new_height = driver.execute_script("return document.body.scrollHeight")
    return new_height > old_height


# ------------------------------------------------
# æå–ç•™è¨€ï¼ˆé‚Šè®€é‚Šå¯« CSVï¼‰
# ------------------------------------------------
def extract_comments(seen):
    comments = driver.find_elements(
        By.XPATH,
        "//div[@role='article' and .//div[@dir='auto']]"
    )

    for c in comments:
        try:
            text_block = c.text.strip()
            if not text_block:
                continue

            # å˜—è©¦å–å¾—ç•™è¨€ permalinkï¼ˆå”¯ä¸€ IDï¼‰
            links = c.find_elements(By.XPATH, ".//a[contains(@href,'comment_id')]")
            if links:
                permalink = links[0].get_attribute("href")
                cid = permalink
            else:
                cid = make_hash(text_block)

            if cid in seen:
                continue

            seen.add(cid)

            # æŠ“ä½œè€…
            author = ""
            try:
                author = c.find_element(By.XPATH, ".//strong//span").text
            except:
                pass

            # æŠ“å…§å®¹ï¼ˆç§»é™¤ä½œè€…ï¼‰
            content = text_block.replace(author, "").strip()

            csv_writer.writerow([cid, author, content])
            print("âœ” å·²å¯«å…¥ç•™è¨€ï¼š", content[:30])

        except Exception as e:
            pass


# ------------------------------------------------
# æ§åˆ¶æ•´é«”æµç¨‹
# ------------------------------------------------
def navigate_comment_section():
    seen = set()

    no_change_count = 0

    while True:
        print("â¡ å±•é–‹æ›´å¤šç•™è¨€/å›è¦†â€¦")
        expanded = expand_all_buttons()

        print("â¡ æå–ç•™è¨€â€¦")
        extract_comments(seen)

        print("â¡ æ»¾å‹•é é¢â€¦")
        scrolled = scroll_page()

        print("page_scrolled, sleep now")
        time.sleep(0.5)

        # è‹¥ç„¡å±•é–‹ä¹Ÿç„¡æ»¾å‹•ï¼Œå¯èƒ½åˆ°åº•
        if not expanded and not scrolled:
            no_change_count += 1
            print("no change count: ",no_change_count)
        else:
            no_change_count = 0
            print("no change count refreshed")

        if no_change_count >= 10:
            print("âœ” å·²åˆ°åº•éƒ¨ï¼Œåœæ­¢")
            break


# ------------------------------------------------
# ä¸»æµç¨‹
# ------------------------------------------------
comment_section = find_comment_section()
navigate_comment_section()

csv_file.close()
driver.quit()

print("ğŸ‰ å®Œæˆï¼ç•™è¨€å·²å¯«å…¥ fb_comments.csv")
