{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a0d5502-2a61-460a-b353-15f6986b8cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bin_l\\anaconda3\\envs\\MIS\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import json\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66b4d6ed-6065-467d-8e7e-9b15ef0c7942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: 0\n",
      "Loading data from fb_comments.json...\n",
      "Loading model: cardiffnlp/twitter-xlm-roberta-base-sentiment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sentiment analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:26<00:00,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to fb_sentiment.json...\n",
      "Saving summary to fb_sentiment_summary.txt...\n",
      "\n",
      "Sentiment Analysis Summary:\n",
      "Total comments processed: 10094\n",
      "正面: 2559\n",
      "中性: 2780\n",
      "負面: 4755\n",
      "\n",
      "Sentiment Distribution by Keyword:\n",
      "Keyword         | Positive   | Neutral    | Negative   | Total   \n",
      "-----------------------------------------------------------------\n",
      "修杰楷             |   20.1%   |   25.1%   |   54.7%   |     4425\n",
      "廖允杰             |   29.7%   |   25.9%   |   44.4%   |      374\n",
      "張書偉             |   51.2%   |   21.1%   |   27.7%   |     2093\n",
      "王大陸             |   12.6%   |   31.0%   |   56.4%   |     1696\n",
      "謝坤達             |   35.5%   |   24.2%   |   40.3%   |      462\n",
      "阿達              |   19.1%   |   49.6%   |   31.3%   |      131\n",
      "陳零九             |    9.0%   |   46.9%   |   44.1%   |      913\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Check for GPU\n",
    "    device = 0 if torch.cuda.is_available() else -1\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Input and Output files\n",
    "    input_file = 'fb_comments.json'\n",
    "    output_file = 'fb_sentiment.json'\n",
    "\n",
    "    # Load data\n",
    "    if not os.path.exists(input_file):\n",
    "        print(f\"File {input_file} not found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Loading data from {input_file}...\")\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Model name\n",
    "    model_name = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "\n",
    "    print(f\"Loading model: {model_name}...\")\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "        \n",
    "        # Move model to device\n",
    "        if device >= 0:\n",
    "            model = model.to(f'cuda:{device}')\n",
    "        \n",
    "        sentiment_pipeline = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer, device=device)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load model: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return\n",
    "\n",
    "    # Label mapping\n",
    "    label_map = {\n",
    "        \"negative\": \"負面\",\n",
    "        \"neutral\": \"中性\",\n",
    "        \"positive\": \"正面\",\n",
    "        \"LABEL_0\": \"負面\",\n",
    "        \"LABEL_1\": \"中性\",\n",
    "        \"LABEL_2\": \"正面\"\n",
    "    }\n",
    "\n",
    "    print(\"Starting sentiment analysis...\")\n",
    "    results = {} # {keyword: [ {comment, sentiment, score}, ... ]}\n",
    "\n",
    "    # Process each keyword\n",
    "    for keyword, comments in tqdm(data.items()):\n",
    "        comment_sentiments = []\n",
    "        \n",
    "        if comments:\n",
    "            try:\n",
    "                # Process comments in batch\n",
    "                predictions = sentiment_pipeline(comments, truncation=True, max_length=512, batch_size=8)\n",
    "                \n",
    "                for comment, pred in zip(comments, predictions):\n",
    "                    sentiment_label = pred['label'].lower() if isinstance(pred['label'], str) else pred['label']\n",
    "                    if sentiment_label in label_map:\n",
    "                        sentiment_zh = label_map[sentiment_label]\n",
    "                    else:\n",
    "                        sentiment_zh = sentiment_label\n",
    "\n",
    "                    comment_sentiments.append({\n",
    "                        \"comment\": comment,\n",
    "                        \"sentiment\": sentiment_zh,\n",
    "                        \"score\": pred['score']\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing comments for keyword {keyword}: {e}\")\n",
    "                # Fallback: process one by one\n",
    "                for comment in comments:\n",
    "                    try:\n",
    "                        pred = sentiment_pipeline(comment, truncation=True, max_length=512)[0]\n",
    "                        sentiment_label = pred['label']\n",
    "                        sentiment_zh = label_map.get(sentiment_label, sentiment_label)\n",
    "                        if sentiment_zh not in [\"正面\", \"中性\", \"負面\"]:\n",
    "                             sentiment_zh = label_map.get(str(sentiment_label).lower(), sentiment_label)\n",
    "\n",
    "                        comment_sentiments.append({\n",
    "                            \"comment\": comment,\n",
    "                            \"sentiment\": sentiment_zh,\n",
    "                            \"score\": pred['score']\n",
    "                        })\n",
    "                    except Exception as inner_e:\n",
    "                        comment_sentiments.append({\n",
    "                            \"comment\": comment,\n",
    "                            \"sentiment\": \"Error\",\n",
    "                            \"score\": 0.0\n",
    "                        })\n",
    "\n",
    "        results[keyword] = comment_sentiments\n",
    "\n",
    "    # Save\n",
    "    print(f\"Saving results to {output_file}...\")\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    # Print summary and save to file\n",
    "    summary_file = 'fb_sentiment_summary.txt'\n",
    "    print(f\"Saving summary to {summary_file}...\")\n",
    "    \n",
    "    with open(summary_file, 'w', encoding='utf-8') as f_summary:\n",
    "        sentiment_counts = {\"正面\": 0, \"中性\": 0, \"負面\": 0}\n",
    "        keyword_stats = {} # {keyword: {\"正面\": 0, \"中性\": 0, \"負面\": 0, \"total\": 0}}\n",
    "\n",
    "        total_comments = 0\n",
    "        for keyword, comments_data in results.items():\n",
    "            if keyword not in keyword_stats:\n",
    "                keyword_stats[keyword] = {\"正面\": 0, \"中性\": 0, \"負面\": 0, \"total\": 0}\n",
    "\n",
    "            for item in comments_data:\n",
    "                s = item.get('sentiment')\n",
    "                \n",
    "                # Global stats\n",
    "                if s in sentiment_counts:\n",
    "                    sentiment_counts[s] += 1\n",
    "                total_comments += 1\n",
    "                \n",
    "                # Keyword stats\n",
    "                if s in keyword_stats[keyword]:\n",
    "                    keyword_stats[keyword][s] += 1\n",
    "                keyword_stats[keyword][\"total\"] += 1\n",
    "                \n",
    "        # Helper to print to both console and file\n",
    "        def print_both(text):\n",
    "            print(text)\n",
    "            f_summary.write(text + \"\\n\")\n",
    "\n",
    "        print_both(\"\\nSentiment Analysis Summary:\")\n",
    "        print_both(f\"Total comments processed: {total_comments}\")\n",
    "        for k, v in sentiment_counts.items():\n",
    "            print_both(f\"{k}: {v}\")\n",
    "\n",
    "        print_both(\"\\nSentiment Distribution by Keyword:\")\n",
    "        print_both(f\"{'Keyword':<15} | {'Positive':<10} | {'Neutral':<10} | {'Negative':<10} | {'Total':<8}\")\n",
    "        print_both(\"-\" * 65)\n",
    "        \n",
    "        for keyword, stats in keyword_stats.items():\n",
    "            total = stats[\"total\"]\n",
    "            if total > 0:\n",
    "                pos_pct = (stats[\"正面\"] / total) * 100\n",
    "                neu_pct = (stats[\"中性\"] / total) * 100\n",
    "                neg_pct = (stats[\"負面\"] / total) * 100\n",
    "                print_both(f\"{keyword:<15} | {pos_pct:>6.1f}%   | {neu_pct:>6.1f}%   | {neg_pct:>6.1f}%   | {total:>8}\")\n",
    "            else:\n",
    "                print_both(f\"{keyword:<15} | {'N/A':>8} | {'N/A':>8} | {'N/A':>8} | {total:>8}\")\n",
    "\n",
    "    print(\"Done.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5041e3ea-0aa1-40bb-ae14-f47ff83d55d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
